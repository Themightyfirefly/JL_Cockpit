var documenterSearchIndex = {"docs":
[{"location":"tutorials/visualiser/#Using-the-visualiser","page":"Using the Visualiser standalone","title":"Using the visualiser","text":"","category":"section"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"JL_Cockpit allows to use the visualiser with your own training implementation. To use the visualiser, call the visualiser function and write the return value to a variable.","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"vis = visualiser()","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"Just like with the training_loop execution, the optional arguments can be used to turn on or turn off the plots. To turn off the visualisation of the loss and gradient norm, run","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"vis = visualiser(vis_loss = false, vis_grad_norm = false)","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"Before the training starts, the original parameter values should be passed to the visualiser, by pushing a Datapoint object to vis.datapoints.","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"push!(vis.datapoints, Datapoint(-1, -1, nothing, nothing, Flux.params(model)))","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"Then the data from the training can be passed in each iteration of the training.","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"push!(vis.datapoints, Datapoint(epoch, iteration, loss, grads, params))","category":"page"},{"location":"tutorials/visualiser/","page":"Using the Visualiser standalone","title":"Using the Visualiser standalone","text":"The vis.datapoint object is a vector inside an Observable. This will ensure that the passed values are automatically used to calculate the metrics and update the plots.","category":"page"},{"location":"getting_started/#Getting-started","page":"Getting Started","title":"Getting started","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"We have created a package to provide a modular monitoring and debugging pipeline for training neural networks, implementing a modular training loop using Flux.jl. This package allows users to specify observable quantities (e.g. gradient norm, curvature). Users can see the live dashboard that we implemented with Makie.jl.","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"The jl_cockpit module provides plots for the live visualisation for neural network training. It uses the GLMakie module and their Observable to provide the live functionality. Using the module can happen in two different ways:","category":"page"},{"location":"getting_started/#Example-Workflow","page":"Getting Started","title":"Example Workflow","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"To add the JL_Cockpit module to your Julia environment run","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"]\nadd https://github.com/Themightyfirefly/JL_Cockpit","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"Once the module has been added, activate the module","category":"page"},{"location":"getting_started/","page":"Getting Started","title":"Getting Started","text":"using JL_Cockpit","category":"page"},{"location":"API/plot_functions/","page":"Plot Functions","title":"Plot Functions","text":"Pages   = [\"plot_functions.md\"]","category":"page"},{"location":"API/plot_functions/#JL_Cockpit.loss_plot!","page":"Plot Functions","title":"JL_Cockpit.loss_plot!","text":"loss_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot the loss of each Datapoint as a line graph.\n\n\n\n\n\nloss_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}})\n\nUse a predefined position (1,1) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/plot_functions/#JL_Cockpit.grad_norm_plot!","page":"Plot Functions","title":"JL_Cockpit.grad_norm_plot!","text":"grad_norm_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot the norm of the gradients in each Datapoint as a line graph. \n\n\n\n\n\ngrad_norm_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}})\n\nUse a predefined position (2,1) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/plot_functions/#JL_Cockpit.hist_1d_plot!","page":"Plot Functions","title":"JL_Cockpit.hist_1d_plot!","text":"hist_1d_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot a histogram of gradients in the last Datapoint.\n\n\n\n\n\nhist_1d_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}})\n\nUse a predefined position (1,2) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/plot_functions/#JL_Cockpit.params_plot!","page":"Plot Functions","title":"JL_Cockpit.params_plot!","text":"params_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot a histogram of the parameters given in the last Datapoint.\n\n\n\n\n\nparams_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}})\n\nUse a predefined position (2,2) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/plot_functions/#JL_Cockpit.distance_plot!","page":"Plot Functions","title":"JL_Cockpit.distance_plot!","text":"distance_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot the l2 distance between the parameters in the first and last Datapoint as a point graph.\n\n\n\n\n\ndistance_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}})\n\nUse the predefined position (1,3) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/plot_functions/#JL_Cockpit.update_size_plot!","page":"Plot Functions","title":"JL_Cockpit.update_size_plot!","text":"update_size_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot the l2 distance between parameters in the second to last and last Datapoint given.\n\n\n\n\n\nupdate_size_plot!(fig::Makie.Figure, datapoints::Observable{Vector{Datapoint}})\n\nUse the predefined position (2,3) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/plot_functions/#JL_Cockpit.hist_2d_plot!","page":"Plot Functions","title":"JL_Cockpit.hist_2d_plot!","text":"hist_2d_plot!(fig, datapoints::Observable{Vector{Datapoint}}, a::Int64, b::Int64)\n\nPlot the Parameters and the corresponding Gradients in the current training iteration.\n\n\n\n\n\nhist_2d_plot!(fig, datapoints::Observable{Vector{Datapoint}})\n\nUse the predefined position (3,1) in Figure, if none is given.\n\n\n\n\n\n","category":"function"},{"location":"API/training_api/","page":"Training and Visualisation API","title":"Training and Visualisation API","text":"Pages   = [\"training_api.md\"]","category":"page"},{"location":"API/training_api/#JL_Cockpit.training_loop","page":"Training and Visualisation API","title":"JL_Cockpit.training_loop","text":"training_loop(;\n    model = nothing, dataset_train = nothing, dataset_test = nothing, \n    batchsize = 128, epochs = 5, optim = nothing,\n    vis_loss::Bool = true, vis_grad_norm::Bool = true, \n    vis_hist_1d::Bool = true, vis_params::Bool = true,\n    vis_distance::Bool = true, vis_update_size::Bool = true, vis_hist_2d::Bool = false\n)\n\nTrain with AD and visualise live metrics.\n\n\n\n\n\n","category":"function"},{"location":"API/training_api/#JL_Cockpit.visualiser","page":"Training and Visualisation API","title":"JL_Cockpit.visualiser","text":"visualiser(;\n    vis_loss::Bool = true, vis_grad_norm::Bool = true, vis_hist_1d::Bool = true, \n    vis_params::Bool = true, vis_distance::Bool = true, vis_update_size::Bool = true, \n    vis_hist_2d::Bool = false\n)\n\nInitialises the visualiser. It will take the given Observables and display a plot that updates live. \n\n\n\n\n\n","category":"function"},{"location":"internal/","page":"Internal Functions","title":"Internal Functions","text":"Pages   = [\"internal.md\"]","category":"page"},{"location":"internal/#JL_Cockpit.preprocess-Tuple{Any}","page":"Internal Functions","title":"JL_Cockpit.preprocess","text":"preprocess(dataset)\n\nTransform x into a 28x28 matrix and y into a 10-class vector.\n\n\n\n\n\n","category":"method"},{"location":"internal/#JL_Cockpit.iterate_plot_pos-Tuple{Int64, Int64}","page":"Internal Functions","title":"JL_Cockpit.iterate_plot_pos","text":"iterate_plot_pos(a::Int64, b::Int64)\n\nIterate the positions in a Figure, so that there are no gaps and the number of rows is never more than the number of columns.\n\n\n\n\n\n","category":"method"},{"location":"internal/#Base.push!-Union{Tuple{T}, Tuple{Observables.Observable{Vector{T}}, T}} where T<:Real","page":"Internal Functions","title":"Base.push!","text":"push!(list_obs::Observable{Vector{T}}, value::T) where {T<:Real}\n\nPush number onto a Vector packaged in the given Observable and trigger Observable.\n\n\n\n\n\n","category":"method"},{"location":"internal/#Base.push!-Tuple{Observables.Observable{Vector{Datapoint}}, Datapoint}","page":"Internal Functions","title":"Base.push!","text":"push!(obs::Observable{Vector{Datapoint}}, dp::Datapoint)\n\nPush Datapoint onto a Vector packaged in the given Observable and trigger Observable.\n\n\n\n\n\n","category":"method"},{"location":"internal/#Base.append!-Union{Tuple{T}, Tuple{Observables.Observable{Vector{T}}, Vector{T}}} where T<:Real","page":"Internal Functions","title":"Base.append!","text":"append!(obs::Observable{Vector{T}}, val_vector::Vector{T}) where {T<:Real}\n\nAppend a Vector of Real numbers to an Observable and trigger the Observable.\n\n\n\n\n\n","category":"method"},{"location":"tutorials/custom_training/#Customising-the-Flux-Training-Loop","page":"Customising the Training","title":"Customising the Flux Training Loop","text":"","category":"section"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"As can be seen in the API reference, the training_loop function can be called with the following optional arguments.","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"training_loop(;\n    model = nothing, dataset_train = nothing, dataset_test = nothing, \n    batchsize = 128, epochs = 5, optim = nothing,\n    vis_loss::Bool = true, vis_grad_norm::Bool = true, \n    vis_hist_1d::Bool = true, vis_params::Bool = true,\n    vis_distance::Bool = true, vis_update_size::Bool = true, vis_hist_2d::Bool = false\n)","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"By default model, dataset_train, dataset_test and optim are not defined and the following default values will be assigned:","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"model = Chain(\n    Conv((5, 5), 1 => 6, relu),  # 1 input color channel\n    MaxPool((2, 2)),\n    Conv((5, 5), 6 => 16, relu),\n    MaxPool((2, 2)),\n    Flux.flatten,\n    Dense(256, 120, relu),\n    Dense(120, 84, relu),\n    Dense(84, 10),  # 10 output classes)\n\ndataset_train = MNIST(; split=:train)\n\ndataset_test = MNIST(; split=:test)\n\noptim = Flux.setup(Adam(3.0f-4), model)","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"Additionally the training is set to run for 5 epochs and the size of the batch used in each iteration is set to 128.","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"These values can be changed by passing the custom values to the training_loop function call, e.g.","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"training_loop(epochs=2)","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"The vis_ arguments determine if a metric is shown. By default, all available metrics, except the 2D histogram of parameter values and gradients, are shown. To deactivate a plot, set the argument to false, e.g.","category":"page"},{"location":"tutorials/custom_training/","page":"Customising the Training","title":"Customising the Training","text":"training_loop(vis_loss=false)","category":"page"},{"location":"#JL_Cockpit","page":"Home","title":"JL_Cockpit","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A visualisation of metrics during a Flux.jl training loop.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: Training Visualisation)","category":"page"},{"location":"#Index-of-all-functions","page":"Home","title":"Index of all functions","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"},{"location":"API/utils/","page":"Utils","title":"Utils","text":"Pages   = [\"utils.md\"]","category":"page"},{"location":"API/utils/#JL_Cockpit.Datapoint","page":"Utils","title":"JL_Cockpit.Datapoint","text":"struct Datapoint\n    epoch::Int\n    batch::Int\n    loss::Union{Float32, Nothing}\n    grads::Union{@NamedTuple{Any}, Nothing}\n    params::Union{Zygote.Params{Zygote.Buffer{Any, Vector{Any}}}, Nothing}\nend\n\nStore the information of one Training iteration.\n\n\n\n\n\n","category":"type"}]
}
